# Seleniumì„ í™œìš©í•´ ì„ ìˆ˜ ë“±ë¡ í˜ì´ì§€ì—ì„œ ì‹ ì²´ ì •ë³´(í‚¤, ëª¸ë¬´ê²Œ ë“±)ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
# ì—°ë„ ë° íŒ€ë³„ë¡œ ì „êµ­ ì„ ìˆ˜ ì‹ ì²´ ë°ì´í„° csvë¥¼ ë§Œë“­ë‹ˆë‹¤.


import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
import time
from google.colab import files

# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
df_2023 = pd.read_csv("/content/KBO_2023_URL.csv")
df_2024 = pd.read_csv("/content/KBO_2024_URL.csv")
df_2025 = pd.read_csv("/content/KBO_2025_URL.csv")

# ì—°ë„ë³„ ë‚ ì§œ 5ê°œì”©ë§Œ ì¶”ì¶œ
dates_2023 = sorted(df_2023['ë‚ ì§œ'].astype(str).unique())[:5]
dates_2024 = sorted(df_2024['ë‚ ì§œ'].astype(str).unique())[:5]
dates_2025 = sorted(df_2025['ë‚ ì§œ'].astype(str).unique())[:5]

# í•©ì¹˜ê¸°
valid_dates = dates_2023 + dates_2024 + dates_2025
print(f"ğŸ“† ì´ {len(valid_dates)}ì¼ í¬ë¡¤ë§ ì˜ˆì •:", valid_dates)

# íŒ€ ë¦¬ìŠ¤íŠ¸
teams = ['HH', 'LG', 'LT', 'HT', 'KT', 'SS', 'SK', 'NC', 'OB', 'WO']

# Chrome ì„¤ì •
chrome_options = Options()
chrome_options.add_argument("--headless")
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")
driver = webdriver.Chrome(options=chrome_options)

all_data = []

# 1ë…„ë‹¹ 5ì¼ë§Œ ìˆœíšŒ
for date_str in valid_dates:
    for team_code in teams:
        print(f"ğŸ“† ë‚ ì§œ: {date_str} | íŒ€: {team_code}")
        driver.get("https://www.koreabaseball.com/Player/Register.aspx")
        time.sleep(1.5)

        # ë‚ ì§œ & íŒ€ ì„¤ì •
        driver.execute_script(f'document.getElementById("cphContents_cphContents_cphContents_hfSearchDate").value = "{date_str}";')
        driver.execute_script(f'document.getElementById("cphContents_cphContents_cphContents_hfSearchTeam").value = "{team_code}";')
        time.sleep(0.5)

        try:
            search_button = driver.find_element(By.ID, "cphContents_cphContents_cphContents_btnCalendarSelect")
            driver.execute_script("arguments[0].click();", search_button)
            time.sleep(2)

            # HTML íŒŒì‹±
            soup = BeautifulSoup(driver.page_source, "html.parser")
            rows = soup.select("table.tNData tbody tr")

            if not rows:
                print("ë“±ë¡ ì •ë³´ ì—†ìŒ (skip)")
                continue

            for row in rows:
                cols = row.find_all("td")
                if len(cols) >= 5:
                    all_data.append({
                        "ë‚ ì§œ": date_str,
                        "íŒ€": team_code,
                        "ì´ë¦„": cols[1].text.strip(),
                        "íˆ¬íƒ€ìœ í˜•": cols[2].text.strip(),
                        "ì²´ê²©": cols[4].text.strip()
                    })
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

driver.quit()

# DataFrameìœ¼ë¡œ ì €ì¥
df = pd.DataFrame(all_data)
csv_name = "KBO_player_register_.csv"
df.to_csv(csv_name, index=False, encoding="utf-8-sig")

# ë‹¤ìš´ë¡œë“œ
files.download(csv_name)
